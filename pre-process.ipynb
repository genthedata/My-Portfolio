{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and cleaning the dataset\n",
    "\n",
    "The following code preprocesses and cleans the dataset.  We read the data from the file, extract the useful data that we wish to use, create our datasets and fill in any NaNs using the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "path_load = 'pp-complete.csv'\n",
    "path_train = 'train.csv'\n",
    "path_val = 'val.csv'\n",
    "path_test = 'test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_num(s):\n",
    "    if str.isnumeric(s):\n",
    "        # check no 'vulgar fractions'\n",
    "        # https://regexr.com/3p8nd\n",
    "        if re.search(r'[\\u2150-\\u215F\\u00BC-\\u00BE\\u2189]', s) == None:\n",
    "            return float(s)\n",
    "        else:\n",
    "            return convert_num(s[:-1])\n",
    "    else:\n",
    "        return np.NaN\n",
    "\n",
    "\n",
    "def is_london(s):\n",
    "    return int(\"LONDON\" in s.upper())\n",
    "\n",
    "\n",
    "cols = [1, 2, 4, 7, 11]\n",
    "names = ['price', 'date', 'prop_type', 'lease', 'in_london']\n",
    "cat_type = CategoricalDtype(categories=list('DSTFO'), ordered=False)\n",
    "types = {'prop_type': cat_type}\n",
    "converters = {'lease': convert_num, 'in_london': is_london}\n",
    "reader = pd.read_csv(path_load, usecols=cols, chunksize=10 ** 7, header=None, names=names,\n",
    "                     parse_dates=[1], dtype=types, converters=converters)\n",
    "\n",
    "\n",
    "def process_chunk(chunk):\n",
    "    # drop rows with too many nan's\n",
    "    chunk = chunk.dropna(subset=['price', 'date'])\n",
    "    chunk = chunk.dropna(thresh=3)\n",
    "\n",
    "    # get dummies (one_hot vectors)\n",
    "    chunk = pd.get_dummies(chunk)\n",
    "\n",
    "    # split into train, val, test sets and drop the 'date' column\n",
    "    chunk['date'] = chunk['date'].dt.year\n",
    "    df_train = chunk[chunk['date'] < 2014].drop('date', axis=1)\n",
    "    df_val = chunk[chunk['date'] == 2014].drop('date', axis=1)\n",
    "    df_test = chunk[chunk['date'] == 2015].drop('date', axis=1)\n",
    "\n",
    "    # fill nan's on train and val set but fill nan's on test set from 2014 data in second step\n",
    "    df_train.lease = df_train.lease.fillna(\n",
    "        df_train.lease.mean()).astype(np.int32)\n",
    "    df_val.lease = df_val.lease.fillna(df_val.lease.mean()).astype(np.int32)\n",
    "\n",
    "    # save data\n",
    "    df_train.to_csv(path_train, mode='a', header=False, index=False)\n",
    "    df_val.to_csv(path_val, mode='a', header=False, index=False)\n",
    "    df_test.to_csv(path_test, mode='a', header=False, index=False)\n",
    "\n",
    "\n",
    "def clean_test_data():\n",
    "    df_val_lease = pd.read_csv(path_val, header=None, usecols=[\n",
    "                               1], index_col=False, squeeze=True)\n",
    "    names_test = ['price', 'lease', 'in_london', 'D', 'S', 'T', 'F', 'O']\n",
    "    df_test = pd.read_csv(path_test, header=None,\n",
    "                          index_col=False, names=names_test)\n",
    "\n",
    "    df_test['lease'] = df_test['lease'].fillna(\n",
    "        df_val_lease.mean()).astype(np.int32)\n",
    "\n",
    "    df_test.to_csv(path_test, mode='w', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in reader:\n",
    "    process_chunk(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now run in bash: shuf train.csv > train_shuf.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"Now run in bash: shuf train.csv > train_shuf.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now run the model in [model.ipynb](model.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
